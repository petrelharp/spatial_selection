\documentclass{article}
\usepackage{amsmath,amssymb}

\newcommand{\var}{\mathop{\mbox{Var}}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\one}{\mathbf{1}}


\begin{document}


\section{Size of inflorescences}

Let the local rate of growth at location $x$ and time $t$ be given by $f(x,t)$,
and for each $x$ and $t$ let $(X^{(x,t)}_{s})_{s \ge t}$ have the distribution of a branching process begun with one individual at $x$ and time $t$,
and let $\kappa^{(x,t)}_s(dz) = \P\{ |X^{(x,t)}_s| \in dz \}$  be the marginal distribution of the size of $X^{(x,t)}$.
For a given mutation rate $\mu$ and population density $\rho(dx)$ we have a Poisson process of inflorescences of rate $\mu \rho$,
each of which having distribution $\kappa$.  
Then the set of inflorescences alive at time $t$ is Poisson, 
and the mean measure of such inflorescences is
\[ \nu(dx,A) = \mu \rho(dx) \int_{-\infty}^t \P\{ X^{(x,s)}_t \in A \} ds .\]
The first thing we'd want to do is to ignore the spatial extent of $X$ and only look at the total number of individuals,
so we need to know
\[ \int_{-\infty}^t \kappa^{(x,s)}_t(dz) ds . \]

Now assume everything is homogeneous, and let $Z_t$ be a continuous-time branching process begun at zero 
and having branching rate $1$ and offspring distribution $\{p_k : k\ge 0\}$.
Suppose that $Z$ has total lifetime $\tau$ and that $\tau$ is finite almost surely.
If we treat each inflorescence as a point mass, then the set of (location, mass) coordinates $(x,z)$
are Poisson with intensity $dx \otimes q(1,z) dz$ where $q(1,z)=q(z)$ is the Green function of $Z$, namely
\[  
  q(y,z) = \E^y \left[ \int_0^\tau \one(Z_t = z) dt \right] = \int_0^\infty P^t_{yz} dt .
\]
and $q$ solves $L q(y,z) = y \sum_k p_k (q(y+k-1,z)-q(y,z)) = \delta_{y=z}$.

If we are interested in the density of ultimately successful influorescences,
we need to futhermore weight by the probability that the offspring of any of the initial (assumed to be small) number of individuals in an inflorescence survive.
If $p_s$ is the probability of survival in the new selective regime,
since the probability that an influorescence of size $z$ survives in the new selective regime is $1 - (1-p_s)^z$,
the mean measure for successful influorescences is
\[
   \mu dx \int_0^\infty (1-F(1-p_s,t)) dt ,
\]
where $F$ is the generating function for $Z_t$ (in the old selective regime),
\[
  F(a,t) = \E[a^{Z_t} \; | \; Z_0 = 1] .
\]
Note that 
if $\phi$ be the generating function for the offspring distribution in the old selective regime,
then $F$ solves
\[
   \partial_t F(a,t) = \phi(F(a,t)) - F(a,t).
\]
If $\phi_+$ be the generating function for the offspring distribution in the new selective regime,
\[
  \phi_+(a) = \sum_k p_k a^k .
\]
Now, $p_s$ is the minimal solution to $\phi_+(a) = a$.

\section{Notes on branching process approximation}

The branching process approximation will be good as long as the probability of "interactions" are small,
i.e.\ we can couple the branching process with the actual density--regulated model.
Let $Z_t(x)$ be the numbers of selected individuals in deme $x$.
If we assume that $Z_t$ is smooth enough, 
the numbers of nearby individuals to interact with is approximately $Z_t(x) \sigma^d$,
and the total number of individuals is about $\rho \sigma^d$,
so the rate of interactions is about $(Z_t(x) \sigma^d)^2/(\rho \sigma^d)$.
Now if $Z$ is a spatial branching process beginning from a single individual at $x=0$ at $t=0$, 
and growing at rate $r$, then 
\[ 
    Z_t(x) \approx \exp(rt - \|x\|^2/(2\sigma^2 t))/ (2 \pi \sigma^2)^{d/2} 
        \le e^{rt} / ( \sigma^2 t)^{d/2}
\]
and so we need $t$ such that
\[
    e^{2rt} t^{-d} << \rho \sigma^{3d} .
\]
or equivalently,
\[
    e^{2rt/d} t^{-1} << \rho^{1/d} \sigma^3 .
\]
This will be true if $t$ is of smaller order than the logarithm of the effective population density, $\log \rho \sigma^d$.

\subsection{On the random delay}

Let $Y_t$ be the total number of offspring coming from a single individual
(in the spatial, density-regulated model).
Then we know that $(Y_t/t)^{1/d} \to v$, 
but we saw from simulations that it looked like $Y_t^{1/d} \approx v(t-\tau)$,
where $\tau$ is the (random) establishment time.
(It would be useful to look at the coefficient of variation of $\tau$.)
Well, we know that at first, $Y_t \approx W e^{rt}$, 
where $W= \lim e^{-rt} Z_t$, and $Z_t$ is the associated branching process,
and $r$ is the growth rate (er, $r=s$?).
And eventually, $\partial_t Y_t^{1/d} \approx v$.
If this switchover happened at a fixed size $C$,
the size at which wavelike behavior took over,
i.e.\ when $W e^{rt} = C$,
then for $\tau = \frac{1}{r}\log(C/W)$ we'd have 
\[
    Y_t = \begin{cases}
        W e^{rt} \quad & t \le \tau \\
        (v (t-\tau))^d + C \quad & t > \tau ,
\end{cases}
\]
which if $C$ is small relative to the scale we look on will look as described above.
So the random delay is $(1/r)\log(C/W)$; and so the mean delay is something like $(1/r)\log C$
and the randomness is determined by $(1/r)\log (1/W)$.

What about how much variance is left in the branching process?
Well, since $Z_{t+s} = \sum_{k=1}^{Z_t} Z^k_{s}$, where $Z^k_s$ are iid copies of $Z_s$,
we have that $\var[Z_{t+s}|Z_t] = Z_t \var[Z_s]$,
and so the coefficient of variation of $Z_{t+s}$ given $Z_t$ is
\begin{align}
   \mathop{CV}[Z_{t+s}|Z_t] &= \frac{\sqrt{Z_t \var[Z_s]}}{ Z_t \E[Z_s] } \\
        &= e^{-rs} \sqrt{ \var[Z_s] } Z^{-1/2} \\
        &\simeq e^{-rt/2} \sqrt{ \var[W] } .
\end{align}

\section{Properties of the mixed model}

Suppose that there are (point masses of) mutations present at time 0 as a Poisson process of rate $\lambda_0$ (calculated above),
and that after time 0 mutations arise at rate $\lambda$.
Suppose that the mutations spread distance $f(t)$ in time $t$, 
and that the volume of the cone of height $t$ is given by $h(t) = \int_0^t \omega_d f(s)^d ds$.

Let $\tau$ denote the time until the origin is adapted.
Then
\begin{align}
   \P \{ \tau > t \} &= \exp \left\{ - \lambda_0 \omega_d f(t)^d - \lambda h(t) \right\}, \quad \mbox{and} \\
   \E [ \tau ] &= \int_0^\infty \exp \left\{ - \lambda_0 \omega_d f(t)^d - \lambda h(t) \right\} .
\end{align}

Let $z_0$ be the mean proportion of space covered by mutations present at time 0.
Then, by the general result on competing inhomogeneous exponentials,
\begin{align}
    z_0 &= \P\{ \mbox{origin reached by mutations from $\lambda_0$ before $\lambda$} \} \\
        &= \int_0^\infty \lambda_0 d \omega_d f'(t) f(t)^{d-1} \exp \left\{ - \lambda_0 \omega_d f(t)^d - \lambda h(t) \right\} dt .
\end{align}
The mean density of new mutations that would have taken off but were prevented by standing variation is
\begin{align}
    \nu_* = \int_0^\infty \lambda \exp\{ - \lambda h(t) \} \left( 1 - \exp\{ -\lambda_0 \omega_d f(t)^d \} \right) dt
\end{align}
and so the mean proportion of new mutations that would be successful in the absence of standing variation, but are prevented by standing variation,
is 
\begin{align}
    z_* = \frac{ \int_0^\infty \lambda \exp\{ - \lambda h(t) \} \left( 1 - \exp\{ -\lambda_0 \omega_d f(t)^d \} \right) dt }
                { \int_0^\infty \lambda \exp\{ - \lambda h(t) \} dt } .
\end{align}

Let $X$ be the distance to the eventually enclosing mutation and $R=f(\tau)$ (see first paper).
Then if $g(t) = \lambda_0 \omega_d f(t)^d + \lambda h(t)$ then $(X,R)$ has density
\[
    d \omega_d x^{d-1} \exp(-g(f^{-1}(r)) dx dr,
\]
so integrating over $r$,
\[
    \P\{ X \in dx \} = dx d \omega_d x^{d-1} \int_x^\infty \exp( - g(f^{-1}(r)) ) dr ,
\]
and
\[
    \E[ X^n ] = \frac{d\omega_d}{n+d} \int_0^\infty r^{n+d} \exp( - g(f^{-1}(r)) ) dr .
\]

If we rescale time by $\alpha$ and space by $\beta$, 
then this transforms $(\lambda_0, \lambda, f(\cdot))$ into $(\lambda_0/\beta^d, \lambda/(\alpha \beta^d), f(\cdot/\alpha)/\beta)$.  
Setting $\beta = \lambda_0^{1/d}$ and $\alpha = \lambda / \lambda_0$, this is mapped to $(1,1,f(\cdot \lambda_0/\lambda)/\lambda_0^{1/d})$.

\subsection{Constant speed}

Now let $f(t) = vt$, so $h(t) = \frac{ \omega_d v^d }{ d+1 } t^{d+1}$.
The integrals that appear above are of the following form:
\begin{align}
  \int_0^\infty t^c \exp \left( - \alpha t^a - \beta t^b \right) dt 
            &= \left( b^{-1} \beta^{ (1-c)/b } \right) \int_0^\infty u^{(c+1-b)/b} \exp\left( - \alpha \beta^{-a/b} u^{a/b} - u \right) du ,
\end{align}
so it suffices to learn something about the function
\begin{equation}
    G(a,b,x) := \int_0^\infty  t^a \exp\left( -x t^b - t \right) dt .
\end{equation}
We will only be interested in this as a function of $x$; 
the coefficients $a$ and $b$ will merely depend on the dimension and what quantity we are calculating.
We can construct a power series for $G$ in $x$:
\begin{align}
    \partial_x^n G(a,b,x) &= \int_0^\infty (-1)^n t^{a+nb} \exp\left( -x t^b - t \right) dt \\
            &= (-1)^n G(a+nb,b,x) , \quad \mbox{so} \\
    \partial_x^n G(a,b,x) \vert_{x=0} &= \Gamma(a+nb+1) .
\end{align}
So, if everything works out, we will have that
\begin{align}
    G(a,b,x) = \sum_{n \ge 0} \frac{(-x)^n}{n!} \Gamma(a+nb+1) .
\end{align}
To check for convergence, note that by Stirling's formula $\Gamma(z) \simeq \sqrt{2\pi/z} (z/e)^z$,
\begin{align}
    \left( \frac{x^n \Gamma(a+nb+1) }{ n! } \right)^{1/n} &\simeq x \frac{ (a+nb+1)^{b+(a+1)/n} }{ (n+1)^{1+1/n} } e^{(1-b)-a/n} \\
        &\simeq C n^{b-1} b^b \\
        &\to 0  \quad \mbox{as } n \to \infty ,
\end{align}
so that the sum converges for all $x$ if $b<1$ (which is the case for us as $b=d/(d+1)$).
Something simliar is noted at the Wikipedia page on the Gaussian integral, and claims such integrals show up in quantum field theory.


A few facts, first.
Using repeatedly the identity $\Gamma(x+1) = x\Gamma(x)$
and the Pochammer symbol $(x)_n = x(x+1)\cdots(x+n-1)$,
note that for $m \in \N$,
\[
    \Gamma(m+y) = (y)_m \Gamma(y).
\]
Also note that for $c$ and $m$ integers,
\[
    (y)_{cm} = c^{cm} \prod_{k=0}^{c-1} (\frac{y+k}{c})_{m} ,
\]
and in particular, that
\[
    (cm+\ell)! = \ell! (\ell+1)_{cm} = \ell! c^{cm} \prod_{k=0}^{c-1} (\frac{\ell+1+k}{c})_m .
\]

Now suppose that $b$ is rational (as will be the case), letting $b = b'/c$ with $b'$ and $c$ positive integers.
Therefore, setting $n = mc+\ell$,
\begin{align}
    G(a,b,x) &= \sum_{\ell=0}^{c-1} \sum_{m \ge 0} \frac{(-x)^{mc+\ell}}{(mc+\ell)!} \Gamma(a+\ell b'/c+mb'+1) \\
            &= \sum_{\ell=0}^{c-1} \sum_{m \ge 0} \frac{(-x)^{mc+\ell}}{(mc+\ell)!} (a+\ell b')_{mb'} \Gamma(a + \ell b') \\
            &= \sum_{\ell=0}^{c-1} \frac{ (-x)^{\ell} }{ \ell! } \Gamma(a + \ell b') \sum_{m \ge 0} ( (-cx)^c / (b')^{b'} )^m 
                    \frac{ \prod_{j=0}^{b'-1} (\frac{ a+b'\ell+j }{ b' } )_m }{ \prod_{k=0}^{c-1} (\frac{\ell+1+k}{c})_m } ,
\end{align}
which is the sum of $c$ (generalized) hypergeometric series.
For these to converge, we need $b' \le c$, e.g.\ $b\le 1$.

In particular, if we let $A=\lambda_0 \omega_d v^d $ and $B=\lambda h(1)$, then 
\begin{align}
    \E[\tau] &= \int_0^\infty e^{-A t^d - B t^{d+1}} dt \\
            &= \frac{B^{1/(d+1)}}{d+1} \int_0^\infty u^{-d/(d+1))} \exp\left( -AB^{-d/(d+1))} u^{d/(d+1)} -u \right) du \\
            &= \frac{B^{1/(d+1)}}{d+1} G \left(-d/(d+1), d/(d+1), A B^{-d/(d+1)} \right) .
\end{align}
So, if $d=1$, then we have {\bf (verify this by usual methods!)}, with $x = AB^{-1/2}$,
\begin{align}
    \E[\tau] &= \frac{\lambda^{1/(2)}}{2} G \left( -1/2, 1/2, x \right) \\
            &= \frac{\lambda^{1/(2)}}{2} \left\{ \Gamma(-1/2) \sum_{m\ge0} (4x^2)^m \frac{ (-1/2)_m }{ (1/2)_m (1)_m } 
                        - x \Gamma(1/2) \sum_{m\ge0} (4x^2)^m \frac{ (1/2)_m }{ (1)_m (3/2)_m }  \right\} \\
            &=  \frac{\lambda^{1/(2)}}{2} \left\{ \Gamma(-1/2) {}_1F_1(-1/2;1/2;4x^2) - x \Gamma(1/2) {}_1F_1(1/2;3/2;4x^2) \right\} \\
            &= \frac{\lambda^{1/(2)}}{2} \left\{ - \Gamma(-1/2) (1/x) \gamma(-1/2,4x^2) - \Gamma(1/2) (1/x) (\sqrt{\pi}/8) (1-\Phi(4x^2)) \right\} .
\end{align}
where $\Phi$ is the error function.

And in $d=2$, since
\begin{align}
    G(-2/3,2/3,x) &= \Gamma(-2/3) \sum_{m\ge0} (\frac{-27 x^3}{4})^m \frac{ (-1/3)_m (1/6)_m }{ (1/3)_m (2/3)_m (1)_m }
                    - x \Gamma(4/3) \sum_{m\ge0} (\frac{-27 x^3}{4})^m \frac{ (2/3)_m (7/6)_m }{ (2/3)_m (1)_m (4/3)_m }
                        + \frac{1}{2} x^2 \Gamma(10/3) \sum_{m\ge0} (\frac{-27 x^3}{4})^m \frac{ (5/3)_m (13/6)_m }{ (2)_m (4/3)_m (5/3)_m } \\
                &= \Gamma(-2/3) {}_2F_2(-1/3,1/6;1/3,2/3;-\frac{27x^2}{4})
                    -x \Gamma(4/3) {}_1F_1(7/6;4/3;-\frac{27x^2}{4})
                       -\frac{1}{2}x^2 \Gamma(10/3) {}_1F_1(13/6;4/3;-\frac{27x^2}{4}) .
\end{align}

\subsection{Mathematica says}

...that 
\begin{align}
    \int_0^\infty \exp\left( - \lambda \pi v^2 (t^2/s_d + t^3) \right) dt 
       = \frac{ 1 }{ 27 s_d } \left(
            \exp\left( - \frac{2 \pi v^2 \lambda}{27 s_d^3} \right) 2 \sqrt{3} \pi 
                \left( I_{-1/3}\left( \frac{2 \pi v^2 \lambda}{27 s_d^3} \right) 
                    + I_{1/3}\left( \frac{2 \pi v^2 \lambda}{27 s_d^3} \right) 
            \right)
            - 9 {}_2F_2\left(\frac{1}{2},1;\frac{2}{3},\frac{4}{3};-\frac{4 \pi v^2 \lambda}{27 s_d^3}\right)
        \right) ,
\end{align}
where $I_n(x)$ is the modified Bessel function of the first kind (solves $z^2 y''(z) + z y'(z) - (z^2 + n^2) y = 0$),
and ${}_2F_2(\cdot)$ is the generalized hypergeometric function.

...and
\begin{align}
    \int_0^\infty \frac{2\lambda \pi v}{s_d} t \exp\left( - \lambda \pi v^2 (t^2/s_d + t^3) \right) dt 
        = \frac{1}{v s_d} - \frac{1}{2 s_d^2} \exp\left( \frac{\pi v^2 \lambda}{4 s_d^2} \right) \pi \sqrt{\lambda} \left( 1 - \Phi\left( \frac{ v \sqrt{\pi \lambda} }{ 2 s_d } \right) \right) .
\end{align}
where $\Phi$ is the Gaussian CDF.

\section{Characteristic lengths}

How to pick appropriate rule-of-thumb parameters?
Recall that before we had $\chi$ being the smallest solution to
\[
    f\left( \frac{1}{\lambda \chi^d \omega_d} \right) = \chi.
\]
Now, suppose we draw a cylinder in space-time with radius $\chi$ and height $t=f^{-1}(\chi)$;
as before we choose $\chi$ so that the mean number of points in this cylinder is unity.
Then
\[
    1 = \lambda_0 \omega_d \chi^d + \lambda \omega_d f^{-1}(\chi) \chi^d ,
\]
and so we choose $\chi$ to be the unique positive solution to 
\[
    f\left( \frac{1 - \lambda_0 \chi^d \omega_d}{\lambda \chi^d \omega_d} \right) = \chi.
\]

As for the proportion of mutations coming from standing variation,
it seems a natural measure would be the mean number of such mutations in such a cylinder,
which is using the definition of $\chi$,
\begin{align*}
    \pi_0 &= \frac{\lambda_0 \omega_d \chi^d }{ \lambda_0 \omega_d \chi^d + \lambda \omega_d f^{-1}(\chi) \chi^d} \\
        & = \frac{ 1 }{ 1 + \lambda f^{-1}(\chi) / \lambda_0 } \\
        &= \lambda_0 \omega_d \chi^d .
\end{align*}

Now, if $f(t) = vt$, then $f^{-1}(r) = r/v$,
and so we have $\chi$ the positive root of
\[
  \omega_d \chi^d (\lambda_0 + \lambda v \chi) = 1 .
\]
If $d=1$ then this is
\[
    \chi = \frac{ \sqrt{ 4 \lambda_0^2 + 2\lambda v } - 2 \lambda_0 }{ 4 \lambda v } .
\]
In $d=2$ ??

\subsection{Mathematica Says}

... (and Wikipedia too) that the solutions to $ax^2 + bx^3 = 1$ are:
let 
\[
   u = \left( -2a^3 + 27b^2 + 3 \sqrt{3} \sqrt{ -4a^3b^2+27b^4} \right)
\]
and $(1, r, \bar r)$ are the cube roots of $1$, with $r=(1+i\sqrt{3})/2$ then
\[
    x = \begin{cases} 
        -\frac{a}{3b} + \frac{ 2^{1/3} a^2 }{ 3 b u^{1/3} } + \frac{ u^{1/3} }{ 3 b 2^{1/3} } \\
        -\frac{a}{3b} + r \frac{ 2^{1/3} a^2 }{ 3 b u^{1/3} } + \bar r \frac{ u^{1/3} }{ 3 b 2^{1/3} } \\
        -\frac{a}{3b} + \bar r \frac{ 2^{1/3} a^2 }{ 3 b u^{1/3} } + r \frac{ u^{1/3} }{ 3 b 2^{1/3} }  .
    \end{cases}
\]
Plugging in $a=\pi \lambda_0$ and $b=\pi \lambda v$ we get
$u = - 2 \pi^3 \lambda_0^3 + 3 \pi^2 \left( 9 v^2 \lambda^2 + \sqrt{ 81 b^4 \lambda^4 - 12 \pi v^2 \lambda^2 \lambda_0^3 } \right)$
... and the whole expression is ugly.

\section{General relationship between various quantities}

We know that there are $\lambda_0$ successful standing variants per unit area;
suppose that there are $\nu_+$ successful new mutants per unit area.
Therefore, $\lambda_0+\nu_+$ is the mean number of successful mutants per unit area (duh),
and $1/(\lambda_0+\nu_+)$ is the mean area associated with a randomly chosen patch.
Let $p_0$ be the proportion of space occupied by standing variants, 
let $a_0$ be the mean area associated with a randomly chosen standing variant,
and let $a_+$ be the mean area associated with a randomly chosen new variant,
so that
\[
    p_0 = \frac{ \lambda_0 a_0 }{ \lambda_0 a_0 + \nu_+ a_+ } = \lambda_0 a_0 ,
\]
since the denominator is equal to 1.

We know how to calculate $p_0$, above, from thinking about the competing exponentials,
which allows us to find $a_0$.

Now, as in the first paper, the mean density of new patches is easy to calculate -- 
$\lambda \nu_+ = \E[\tau]$, where $\tau$ is the mean adaptation time of a point;
this is because 
\begin{align*}
    \P\{ \tau > t \} &= \P\{ \mbox{no points in $t$-cone} \} \\
            &= (1/\lambda) \P\{ \mbox{new successful adaptation arises in non-occupied $(t+dt,x+dx)$} \} ;
\end{align*}
integrating over $t$ produces the result.

Finally, the proportion of patches that come from new mutation is $\nu_+ / (\nu_+ + \lambda_0)$,
and we know that, conditioning on the type of a randomly chosen patch,
\[
    \frac{1}{\lambda_0+\nu_+} = \frac{\lambda_0}{\lambda_0+\nu_+} a_0 + \frac{\nu_+}{\lambda_0+\nu_+} a_+ .
\]
So, given $\lambda_0$, $\nu_+$, and $a_0$, we can find $a_+$.


\section{Poisson--Vorono\u\i\ facts}

Fill in some facts about PV tesselations.

\end{document}
